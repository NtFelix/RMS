name: Run Tests

on:
  push:
    branches: [main, develop]
    paths:
      - '**/*.ts'
      - '**/*.tsx'
      - '**/*.js'
      - '**/*.jsx'
      - '**/package.json'
      - '**/package-lock.json'
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  NODE_ENV: test
  CI: true
  NODE_OPTIONS: --max-old-space-size=4096
  JEST_TIMEOUT: '10000'
  FORCE_COLOR: '1'

jobs:
  # Setup job to dynamically discover test files and determine which need to run
  setup:
    name: Discover & Filter Test Files
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      total-files: ${{ steps.set-matrix.outputs.total-files }}
      files-to-test: ${{ steps.set-matrix.outputs.files-to-test }}
      is-full-run: ${{ steps.set-matrix.outputs.is-full-run }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for changed file detection

      # Restore cache of previously passing tests
      - name: Restore passing tests cache
        id: cache-passing-tests
        uses: actions/cache/restore@v4
        with:
          path: .test-cache
          key: passing-tests-${{ runner.os }}-dummy-key-for-restore
          restore-keys: |
            passing-tests-${{ runner.os }}-

      # Get changed files for PR or push
      - name: Get changed files
        id: changed-files
        run: |
          # Determine if this is a PR or a push
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            HEAD_SHA="${{ github.event.pull_request.head.sha }}"
          else
            # For push events, compare with the previous commit
            BASE_SHA="${{ github.event.before }}"
            HEAD_SHA="${{ github.sha }}"
            
            # If before is empty (first push), use parent commit
            if [ -z "$BASE_SHA" ] || [ "$BASE_SHA" = "0000000000000000000000000000000000000000" ]; then
              BASE_SHA=$(git rev-parse HEAD~1 2>/dev/null || echo "")
            fi
          fi
          
          echo "Base SHA: $BASE_SHA"
          echo "Head SHA: $HEAD_SHA"
          
          # Get changed files
          if [ -n "$BASE_SHA" ]; then
            CHANGED_FILES=$(git diff --name-only "$BASE_SHA" "$HEAD_SHA" 2>/dev/null | grep -E '\.(ts|tsx|js|jsx)$' || echo "")
          else
            # Fallback: consider all source files as changed
            CHANGED_FILES="ALL"
          fi
          
          echo "Changed files:"
          echo "$CHANGED_FILES"
          
          # Save to file for next step
          echo "$CHANGED_FILES" > changed_files.txt
          
          # Output for debugging
          if [ "$CHANGED_FILES" = "ALL" ]; then
            echo "all-changed=true" >> $GITHUB_OUTPUT
            echo "changed-count=all" >> $GITHUB_OUTPUT
          elif [ -z "$CHANGED_FILES" ]; then
            echo "all-changed=false" >> $GITHUB_OUTPUT
            echo "changed-count=0" >> $GITHUB_OUTPUT
          else
            # Count non-empty lines properly
            CHANGED_COUNT=$(echo "$CHANGED_FILES" | grep -c -v '^$' 2>/dev/null || echo "0")
            echo "all-changed=false" >> $GITHUB_OUTPUT
            echo "changed-count=${CHANGED_COUNT}" >> $GITHUB_OUTPUT
          fi

      - name: Find and filter test files
        id: set-matrix
        run: |
          # Find all test files
          ALL_TEST_FILES=$(find . -type f \( -name "*.test.ts" -o -name "*.test.tsx" \) \
            -not -path "./node_modules/*" \
            -not -path "./.next/*" \
            -not -path "./coverage/*" \
            -not -path "./.git/*" \
            | sed 's|^\./||' \
            | sort)
          
          mapfile -t ALL_FILES_ARRAY <<< "$ALL_TEST_FILES"
          TOTAL_ALL_FILES=${#ALL_FILES_ARRAY[@]}
          
          echo "Found $TOTAL_ALL_FILES total test files"
          
          # Determine if we should run all tests or just changed ones
          IS_MAIN_BRANCH=false
          IS_FULL_RUN=false
          
          if [ "${{ github.ref }}" = "refs/heads/main" ] || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            IS_MAIN_BRANCH=true
            IS_FULL_RUN=true
            echo "Main branch or manual trigger - running ALL tests"
          fi
          
          # Load passing tests cache
          PASSING_TESTS_FILE=".test-cache/passing-tests.json"
          if [ -f "$PASSING_TESTS_FILE" ]; then
            echo "Found passing tests cache"
            cat "$PASSING_TESTS_FILE" | head -20
          else
            echo "No passing tests cache found - will run all tests"
            IS_FULL_RUN=true
            mkdir -p .test-cache
            echo '{}' > "$PASSING_TESTS_FILE"
          fi
          
          # Read changed files
          CHANGED_FILES=$(cat changed_files.txt)
          
          if [ "$CHANGED_FILES" = "ALL" ]; then
            echo "Cannot determine changed files - running all tests"
            IS_FULL_RUN=true
          fi
          
          # Determine which test files to run
          TEST_FILES_TO_RUN=""
          SKIPPED_FILES=""
          
          if [ "$IS_FULL_RUN" = "true" ]; then
            TEST_FILES_TO_RUN="$ALL_TEST_FILES"
            echo "Running all $TOTAL_ALL_FILES tests (full run)"
          else
            echo "Smart mode: checking which tests need to run..."
            
            for TEST_FILE in "${ALL_FILES_ARRAY[@]}"; do
              SHOULD_RUN=false
              
              # Check if the test file itself was changed
              if grep -Fxq "$TEST_FILE" changed_files.txt 2>/dev/null; then
                echo "  ‚úì $TEST_FILE - changed directly"
                SHOULD_RUN=true
              fi
              
              # Check if any related source file was changed
              # Extract the source file path that this test might be testing
              SOURCE_FILE=$(echo "$TEST_FILE" | sed 's|__tests__/||g' | sed 's|\.test\.tsx\?$|.tsx|' | sed 's|\.test\.ts$|.ts|')
              SOURCE_FILE_ALT=$(echo "$TEST_FILE" | sed 's|__tests__/||g' | sed 's|\.test\.tsx\?$|.ts|')
              
              if grep -q "$SOURCE_FILE" changed_files.txt 2>/dev/null || grep -q "$SOURCE_FILE_ALT" changed_files.txt 2>/dev/null; then
                echo "  ‚úì $TEST_FILE - related source changed"
                SHOULD_RUN=true
              fi
              
              # Check if test was previously passing (if not, run it again)
              if [ "$SHOULD_RUN" = "false" ]; then
                # Calculate hash of test file content
                if [ -f "$TEST_FILE" ]; then
                  FILE_HASH=$(md5sum "$TEST_FILE" | cut -d' ' -f1)
                  CACHED_HASH=$(jq -r --arg file "$TEST_FILE" '.[$file] // ""' "$PASSING_TESTS_FILE")
                  
                  if [ "$FILE_HASH" = "$CACHED_HASH" ]; then
                    echo "  ‚è≠ $TEST_FILE - cached as passing (skipping)"
                    SKIPPED_FILES="$SKIPPED_FILES $TEST_FILE"
                  else
                    echo "  ‚úì $TEST_FILE - content changed or not in cache"
                    SHOULD_RUN=true
                  fi
                else
                  SHOULD_RUN=true
                fi
              fi
              
              if [ "$SHOULD_RUN" = "true" ]; then
                TEST_FILES_TO_RUN="$TEST_FILES_TO_RUN $TEST_FILE"
              fi
            done
          fi
          
          # Trim and convert to array
          # Trim and convert to array
          TEST_FILES_TO_RUN=$(echo "$TEST_FILES_TO_RUN" | xargs)
          
          if [ -z "$TEST_FILES_TO_RUN" ]; then
            FILES_ARRAY=()
          else
            # Ensure grep doesn't fail the script if no lines match (though -z check covers most cases)
            mapfile -t FILES_ARRAY <<< "$(echo "$TEST_FILES_TO_RUN" | tr ' ' '\n' | grep -v '^$' || true)"
          fi
          
          TOTAL_FILES=${#FILES_ARRAY[@]}
          
          # Count skipped
          SKIPPED_COUNT=$(echo "$SKIPPED_FILES" | wc -w | xargs)
          
          echo ""
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo "üìä Test Summary:"
          echo "   Total test files:  $TOTAL_ALL_FILES"
          echo "   Skipped (cached):  $SKIPPED_COUNT"
          echo "   Running:           $TOTAL_FILES"
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          
          echo "total-files=$TOTAL_FILES" >> $GITHUB_OUTPUT
          echo "is-full-run=$IS_FULL_RUN" >> $GITHUB_OUTPUT
          
          if [ "$TOTAL_FILES" -eq 0 ]; then
            echo "No tests to run!"
            echo 'matrix={"include":[]}' >> $GITHUB_OUTPUT
            echo "files-to-test=" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Number of parallel runners
          NUM_GROUPS=3
          
          # Partition files into groups using round-robin for even distribution
          GROUP1_FILES=""
          GROUP2_FILES=""
          GROUP3_FILES=""
          
          INDEX=0
          for FILE in "${FILES_ARRAY[@]}"; do
            if [ -n "$FILE" ]; then
              GROUP_NUM=$(( (INDEX % NUM_GROUPS) + 1 ))
              case $GROUP_NUM in
                1) GROUP1_FILES="$GROUP1_FILES $FILE" ;;
                2) GROUP2_FILES="$GROUP2_FILES $FILE" ;;
                3) GROUP3_FILES="$GROUP3_FILES $FILE" ;;
              esac
              INDEX=$((INDEX + 1))
            fi
          done
          
          # Trim leading spaces
          GROUP1_FILES=$(echo "$GROUP1_FILES" | xargs)
          GROUP2_FILES=$(echo "$GROUP2_FILES" | xargs)
          GROUP3_FILES=$(echo "$GROUP3_FILES" | xargs)
          
          # Count files per group
          GROUP1_COUNT=$(echo "$GROUP1_FILES" | wc -w | xargs)
          GROUP2_COUNT=$(echo "$GROUP2_FILES" | wc -w | xargs)
          GROUP3_COUNT=$(echo "$GROUP3_FILES" | wc -w | xargs)
          
          echo ""
          echo "Distribution across runners:"
          echo "  Group 1: $GROUP1_COUNT files"
          echo "  Group 2: $GROUP2_COUNT files"
          echo "  Group 3: $GROUP3_COUNT files"
          
          # Build matrix JSON - only include groups with files
          INCLUDE_ARRAY="["
          FIRST=true
          
          if [ -n "$GROUP1_FILES" ]; then
            [ "$FIRST" = "false" ] && INCLUDE_ARRAY="$INCLUDE_ARRAY,"
            INCLUDE_ARRAY="$INCLUDE_ARRAY{\"test-group\":1,\"is-first-group\":true,\"test-files\":$(echo "$GROUP1_FILES" | jq -R .)}"
            FIRST=false
          fi
          
          if [ -n "$GROUP2_FILES" ]; then
            [ "$FIRST" = "false" ] && INCLUDE_ARRAY="$INCLUDE_ARRAY,"
            INCLUDE_ARRAY="$INCLUDE_ARRAY{\"test-group\":2,\"is-first-group\":false,\"test-files\":$(echo "$GROUP2_FILES" | jq -R .)}"
            FIRST=false
          fi
          
          if [ -n "$GROUP3_FILES" ]; then
            [ "$FIRST" = "false" ] && INCLUDE_ARRAY="$INCLUDE_ARRAY,"
            INCLUDE_ARRAY="$INCLUDE_ARRAY{\"test-group\":3,\"is-first-group\":false,\"test-files\":$(echo "$GROUP3_FILES" | jq -R .)}"
            FIRST=false
          fi
          
          INCLUDE_ARRAY="$INCLUDE_ARRAY]"
          MATRIX_JSON="{\"include\":$INCLUDE_ARRAY}"
          
          echo ""
          echo "Matrix JSON:"
          echo "$MATRIX_JSON" | jq .
          
          # Output
          echo "matrix=$(echo "$MATRIX_JSON" | jq -c .)" >> $GITHUB_OUTPUT
          echo "files-to-test=$TEST_FILES_TO_RUN" >> $GITHUB_OUTPUT

  # E2E Tests with Playwright - runs in parallel with unit tests
  e2e-test:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: setup
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Cache node_modules
        uses: actions/cache@v4
        id: cache-node-modules
        with:
          path: node_modules
          key: ${{ runner.os }}-node-modules-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-modules-

      - name: Install dependencies
        if: steps.cache-node-modules.outputs.cache-hit != 'true'
        run: npm ci --prefer-offline

      - name: Install Playwright Browsers
        run: npx playwright install --with-deps

      - name: Build application
        run: npm run build
        env:
          # Add any required build-time environment variables
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL || 'http://localhost:54321' }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY || 'mock-anon-key' }}

      - name: Run Playwright tests
        run: npx playwright test
        env:
          CI: true
          # Use production build for E2E tests
          NODE_ENV: production

      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: ${{ !cancelled() }}
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 30

      - name: Upload Playwright test results
        uses: actions/upload-artifact@v4
        if: ${{ !cancelled() }}
        with:
          name: playwright-test-results
          path: test-results/
          retention-days: 7

  test:
    name: Run Tests (Group ${{ matrix.test-group }})
    runs-on: ubuntu-latest
    needs: setup
    if: ${{ needs.setup.outputs.total-files != '0' }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}
    
    # Job name is set by the matrix strategy
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Setup Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Cache node_modules (shared with Lighthouse workflow)
      - name: Cache node_modules
        uses: actions/cache@v4
        id: cache-node-modules
        with:
          path: node_modules
          key: ${{ runner.os }}-node-modules-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-modules-

      # Cache Jest test results
      - name: Cache Jest
        uses: actions/cache@v4
        id: cache-jest
        with:
          path: .jest/cache
          key: ${{ runner.os }}-jest-${{ hashFiles('**/*.test.ts', '**/*.test.tsx') }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-jest-

      # Install dependencies (skip if cache hit)
      - name: Install dependencies
        if: steps.cache-node-modules.outputs.cache-hit != 'true'
        run: npm ci --prefer-offline

      # Get test files for this group
      - name: Get test files list
        id: test-files
        run: |
          # Create a JSON array of test files from the matrix variable
          TEST_FILES_RAW="${{ matrix.test-files }}"
          
          if [ -z "$TEST_FILES_RAW" ]; then
            echo "No test files specified for this group"
            echo "[]" > test_files.json
          else
            # Convert space and newline-separated list to JSON array
            # First normalize whitespace, then split on spaces/newlines
            echo "$TEST_FILES_RAW" | tr -s '[:space:]' '\n' | grep -v '^[[:space:]]*$' | jq -R . | jq -s . > test_files.json
          fi
          
          # Validate JSON
          if ! jq -e . test_files.json > /dev/null 2>&1; then
            echo "Error: Invalid JSON in test_files.json"
            cat test_files.json
            exit 1
          fi
          
          # Output for debugging
          echo "Test files in group ${{ matrix.test-group }}:"
          cat test_files.json
          echo "Number of test files: $(jq 'length' test_files.json)"
          
          # Set output for use in subsequent steps
          echo "test_files=$(cat test_files.json | jq -c .)" >> $GITHUB_OUTPUT

      # Run tests for this group
      - name: Run test group ${{ matrix.test-group }}
        timeout-minutes: 5
        run: |
          # Clean any previous coverage data
          rm -rf coverage/ .nyc_output/
          
          # Check if we have any test files
          if [ ! -f test_files.json ] || [ "$(jq 'length' test_files.json)" -eq 0 ]; then
            echo "No test files found in this group. Skipping test execution."
            # Create empty coverage directory if this is the first group
            if [ "${{ matrix.is-first-group }}" = "true" ]; then
              mkdir -p coverage
              echo '{"total": {"lines": {"pct": 100}, "statements": {"pct": 100}, "functions": {"pct": 100}, "branches": {"pct": 100}}}' > coverage/coverage-summary.json
            fi
            exit 0
          fi
          
          # Build jest command with proper arguments for stability
          JEST_ARGS="--runInBand --forceExit --detectOpenHandles --testTimeout=10000 --passWithNoTests --no-cache"
          
          # Only add coverage for the first group to avoid merge conflicts
          if [ "${{ matrix.is-first-group }}" = "true" ]; then
            mkdir -p coverage
            JEST_ARGS="$JEST_ARGS --coverage --testLocationInResults --json --outputFile=test-results.json"
          fi
          
          # Read test files into an array to handle paths with special characters
          mapfile -t TEST_FILES_ARRAY < <(jq -r '.[]' test_files.json)
          
          if [ ${#TEST_FILES_ARRAY[@]} -eq 0 ]; then
            echo "No test files to run in this group."
            if [ "${{ matrix.is-first-group }}" = "true" ]; then
              mkdir -p coverage
              echo '{"total": {"lines": {"pct": 100}, "statements": {"pct": 100}, "functions": {"pct": 100}, "branches": {"pct": 100}}}' > coverage/coverage-summary.json
            fi
            exit 0
          fi
          
          echo "Running test group ${{ matrix.test-group }} with ${#TEST_FILES_ARRAY[@]} test files"
          
          # Execute tests with proper quoting and timeout handling
          timeout 180 npx jest $JEST_ARGS "${TEST_FILES_ARRAY[@]}" 2>&1 | tee jest-output.log || {
            TEST_EXIT_CODE=$?
            if [ $TEST_EXIT_CODE -eq 124 ]; then
              echo "Tests timed out after 3 minutes"
              exit 1
            fi
            exit $TEST_EXIT_CODE
          }
          TEST_EXIT_CODE=$?
          
          # If this is the first group, ensure coverage directory exists
          if [ "${{ matrix.is-first-group }}" = "true" ] && [ ! -d "coverage" ]; then
            mkdir -p coverage
            echo '{"total": {"lines": {"pct": 0}, "statements": {"pct": 0}, "functions": {"pct": 0}, "branches": {"pct": 0}}}' > coverage/coverage-summary.json
          fi
          
          # For the first group, verify coverage
          if [ "${{ matrix.is-first-group }}" = "true" ] && [ -d "coverage" ]; then
            echo "Coverage report generated at: $(pwd)/coverage"
            ls -la coverage/ || echo "Coverage directory is empty"
          fi
          
          # Exit with the test status code
          exit $TEST_EXIT_CODE

      # Upload test results as artifacts (only from first group)
      - name: Upload test results
        if: always() && matrix.is-first-group
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            coverage/
            test-results.json
          if-no-files-found: ignore
          retention-days: 7
          
      # Upload JUnit test results for better visualization
      - name: Upload JUnit test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-group-${{ matrix.test-group }}
          path: |
            junit-*.xml
          if-no-files-found: ignore
          retention-days: 7

      # Save test results summary for this group
      - name: Save test summary
        if: always()
        run: |
          # Create a summary file for this group
          mkdir -p test-summaries
          
          # Initialize variables
          PASSED=0
          FAILED=0
          TOTAL=0
          SUITES_PASSED=0
          SUITES_FAILED=0
          SUITES_TOTAL=0
          
          # Extract test results from Jest output if available
          if [ -f "test-results.json" ]; then
            echo "Found test-results.json, parsing..."
            cat test-results.json
            
            PASSED=$(jq -r '.numPassedTests // 0' test-results.json)
            FAILED=$(jq -r '.numFailedTests // 0' test-results.json)
            TOTAL=$(jq -r '.numTotalTests // 0' test-results.json)
            
            SUITES_PASSED=$(jq -r '.numPassedTestSuites // 0' test-results.json)
            SUITES_FAILED=$(jq -r '.numFailedTestSuites // 0' test-results.json)
            SUITES_TOTAL=$(jq -r '.numTotalTestSuites // 0' test-results.json)
            
            echo "Parsed from JSON - Tests: P:$PASSED F:$FAILED T:$TOTAL, Suites: P:$SUITES_PASSED F:$SUITES_FAILED T:$SUITES_TOTAL"
          else
            echo "No test-results.json found, checking for jest output..."
            
            # Try to parse from jest output log if available
            if [ -f "jest-output.log" ]; then
              echo "Parsing jest output log..."
              
              # Extract test counts from Jest summary line
              JEST_SUMMARY=$(grep -E "Test Suites:|Tests:" jest-output.log | tail -2)
              echo "Jest summary: $JEST_SUMMARY"
              
              # Parse test suites line: "Test Suites: X failed, Y passed, Z total"
              SUITES_LINE=$(echo "$JEST_SUMMARY" | grep "Test Suites:" || echo "")
              if [ -n "$SUITES_LINE" ]; then
                SUITES_FAILED=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ failed' | grep -o '[0-9]\+' || echo "0")
                SUITES_PASSED=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' || echo "0")
                SUITES_TOTAL=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' || echo "0")
              fi
              
              # Parse tests line: "Tests: X failed, Y passed, Z total"
              TESTS_LINE=$(echo "$JEST_SUMMARY" | grep "Tests:" || echo "")
              if [ -n "$TESTS_LINE" ]; then
                FAILED=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ failed' | grep -o '[0-9]\+' || echo "0")
                PASSED=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' || echo "0")
                TOTAL=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' || echo "0")
              fi
              
              echo "Parsed from log - Tests: P:$PASSED F:$FAILED T:$TOTAL, Suites: P:$SUITES_PASSED F:$SUITES_FAILED T:$SUITES_TOTAL"
            else
              echo "No jest output found, using job status..."
              # Fallback based on job status
              if [ "${{ job.status }}" = "success" ]; then
                PASSED=0
                FAILED=0
                TOTAL=0
                SUITES_PASSED=0
                SUITES_FAILED=0
                SUITES_TOTAL=0
              else
                PASSED=0
                FAILED=1
                TOTAL=1
                SUITES_PASSED=0
                SUITES_FAILED=1
                SUITES_TOTAL=1
              fi
            fi
          fi
          
          # Create summary JSON
          cat > test-summaries/group-${{ matrix.test-group }}.json <<EOF
          {
            "group": ${{ matrix.test-group }},
            "tests": {
              "passed": $PASSED,
              "failed": $FAILED,
              "total": $TOTAL
            },
            "suites": {
              "passed": $SUITES_PASSED,
              "failed": $SUITES_FAILED,
              "total": $SUITES_TOTAL
            },
            "status": "${{ job.status }}"
          }
          EOF
          
          cat test-summaries/group-${{ matrix.test-group }}.json

      # Record passing tests for cache
      - name: Record passing tests
        if: success()
        run: |
          # Only record passing tests if all tests in this group passed
          echo "Recording passing tests for group ${{ matrix.test-group }}..."
          
          mkdir -p .test-cache
          PASSING_TESTS_FILE=".test-cache/passing-tests-group-${{ matrix.test-group }}.json"
          
          # Start with empty JSON object
          echo '{}' > "$PASSING_TESTS_FILE"
          
          # Read test files that were run in this group
          if [ -f test_files.json ]; then
            TEST_FILES=$(jq -r '.[]' test_files.json)
            
            # For each passing test file, record its content hash
            for TEST_FILE in $TEST_FILES; do
              if [ -f "$TEST_FILE" ]; then
                FILE_HASH=$(md5sum "$TEST_FILE" | cut -d' ' -f1)
                # Add to JSON using jq
                jq --arg file "$TEST_FILE" --arg hash "$FILE_HASH" '. + {($file): $hash}' "$PASSING_TESTS_FILE" > tmp.json && mv tmp.json "$PASSING_TESTS_FILE"
                echo "  ‚úì Recorded: $TEST_FILE ($FILE_HASH)"
              fi
            done
          fi
          
          echo "Recorded $(jq 'length' "$PASSING_TESTS_FILE") passing tests for group ${{ matrix.test-group }}"

      # Upload passing tests data for cache update
      - name: Upload passing tests data
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: passing-tests-group-${{ matrix.test-group }}
          path: .test-cache/passing-tests-group-${{ matrix.test-group }}.json
          retention-days: 30
      
      # Upload test summary
      - name: Upload test summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-summary-${{ matrix.test-group }}
          path: test-summaries/
          retention-days: 1

  # Summary job that runs after all test groups complete
  test-summary:
    name: Test Summary & Notification
    runs-on: ubuntu-latest
    needs: [test, e2e-test]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Download all test summaries
      - name: Download test summaries
        uses: actions/download-artifact@v4
        with:
          pattern: test-summary-*
          path: test-summaries
          merge-multiple: true

      # Download Playwright report
      - name: Download Playwright report
        uses: actions/download-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
        continue-on-error: true

      # Download passing tests data from all groups
      - name: Download passing tests data
        uses: actions/download-artifact@v4
        with:
          pattern: passing-tests-group-*
          path: passing-tests-data
          merge-multiple: true
        continue-on-error: true

      # Restore and update passing tests cache
      - name: Restore passing tests cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: .test-cache
          key: passing-tests-${{ runner.os }}-dummy-key-for-restore
          restore-keys: |
            passing-tests-${{ runner.os }}-

      # Merge passing tests from all groups into cache
      - name: Merge passing tests cache
        run: |
          mkdir -p .test-cache
          CACHE_FILE=".test-cache/passing-tests.json"
          
          # Start with existing cache or empty object
          if [ -f "$CACHE_FILE" ]; then
            echo "Loading existing cache with $(jq 'length' "$CACHE_FILE") entries"
          else
            echo '{}' > "$CACHE_FILE"
            echo "Starting with empty cache"
          fi
          
          # Merge all group passing tests files
          if [ -d "passing-tests-data" ]; then
            echo "Merging passing tests from groups..."
            for GROUP_FILE in passing-tests-data/*.json; do
              if [ -f "$GROUP_FILE" ]; then
                echo "  Merging: $GROUP_FILE ($(jq 'length' "$GROUP_FILE") entries)"
                # Merge: newer entries override older ones
                jq -s '.[0] * .[1]' "$CACHE_FILE" "$GROUP_FILE" > tmp.json && mv tmp.json "$CACHE_FILE"
              fi
            done
          else
            echo "No passing tests data to merge"
          fi
          
          FINAL_COUNT=$(jq 'length' "$CACHE_FILE")
          echo ""
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo "üì¶ Passing Tests Cache Updated"
          echo "   Total cached tests: $FINAL_COUNT"
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

      # Save updated passing tests cache
      # Note: GitHub cache keys are immutable, so we use run_id + timestamp to ensure uniqueness
      - name: Save passing tests cache
        if: success()
        uses: actions/cache/save@v4
        with:
          path: .test-cache
          key: passing-tests-${{ runner.os }}-${{ github.run_id }}-${{ github.run_attempt }}
        continue-on-error: true
      
      # Aggregate results and send Discord notification
      - name: Aggregate results and notify Discord
        if: always()
        run: |
          # Aggregate all test results
          TOTAL_TESTS_PASSED=0
          TOTAL_TESTS_FAILED=0
          TOTAL_TESTS=0
          TOTAL_SUITES_PASSED=0
          TOTAL_SUITES_FAILED=0
          TOTAL_SUITES=0
          FAILED_GROUPS=""
          
          echo "Processing test summary files..."
          ls -la test-summaries/ || echo "No test-summaries directory found"
          
          for file in test-summaries/*.json; do
            if [ -f "$file" ]; then
              echo "Processing file: $file"
              cat "$file"
              
              TESTS_PASSED=$(jq -r '.tests.passed' "$file")
              TESTS_FAILED=$(jq -r '.tests.failed' "$file")
              TESTS_TOTAL=$(jq -r '.tests.total' "$file")
              
              SUITES_PASSED=$(jq -r '.suites.passed' "$file")
              SUITES_FAILED=$(jq -r '.suites.failed' "$file")
              SUITES_TOTAL=$(jq -r '.suites.total' "$file")
              
              GROUP=$(jq -r '.group' "$file")
              STATUS=$(jq -r '.status' "$file")
              
              echo "Group $GROUP: Tests P:$TESTS_PASSED F:$TESTS_FAILED T:$TESTS_TOTAL, Suites P:$SUITES_PASSED F:$SUITES_FAILED T:$SUITES_TOTAL, Status:$STATUS"
              
              TOTAL_TESTS_PASSED=$((TOTAL_TESTS_PASSED + TESTS_PASSED))
              TOTAL_TESTS_FAILED=$((TOTAL_TESTS_FAILED + TESTS_FAILED))
              TOTAL_TESTS=$((TOTAL_TESTS + TESTS_TOTAL))
              
              TOTAL_SUITES_PASSED=$((TOTAL_SUITES_PASSED + SUITES_PASSED))
              TOTAL_SUITES_FAILED=$((TOTAL_SUITES_FAILED + SUITES_FAILED))
              TOTAL_SUITES=$((TOTAL_SUITES + SUITES_TOTAL))
              
              if [ "$TESTS_FAILED" -gt 0 ] || [ "$STATUS" != "success" ]; then
                FAILED_GROUPS="$FAILED_GROUPS Group $GROUP: $TESTS_FAILED tests failed in $SUITES_FAILED suites\n"
              fi
            fi
          done
          
          echo "Final aggregated totals:"
          echo "Tests - Passed: $TOTAL_TESTS_PASSED, Failed: $TOTAL_TESTS_FAILED, Total: $TOTAL_TESTS"
          echo "Suites - Passed: $TOTAL_SUITES_PASSED, Failed: $TOTAL_SUITES_FAILED, Total: $TOTAL_SUITES"
          
          echo "Total Tests: $TOTAL_TESTS (Passed: $TOTAL_TESTS_PASSED, Failed: $TOTAL_TESTS_FAILED)"
          echo "Total Suites: $TOTAL_SUITES (Passed: $TOTAL_SUITES_PASSED, Failed: $TOTAL_SUITES_FAILED)"
          
          # Check E2E test status from job needs context
          E2E_STATUS="${{ needs.e2e-test.result }}"
          echo "E2E Test Status: $E2E_STATUS"
          
          E2E_FAILED=false
          if [ "$E2E_STATUS" = "failure" ] || [ "$E2E_STATUS" = "cancelled" ]; then
            E2E_FAILED=true
          fi
          
          # Send Discord notification for both success and failure
          if [ "$TOTAL_TESTS_FAILED" -gt 0 ] || [ "$TOTAL_SUITES_FAILED" -gt 0 ] || [ "$E2E_FAILED" = "true" ]; then
            NOTIFICATION_COLOR=15158332  # Red for failures
            if [ "$E2E_FAILED" = "true" ] && [ "$TOTAL_TESTS_FAILED" -eq 0 ]; then
              NOTIFICATION_TITLE="‚ùå E2E Tests Failed"
            else
              NOTIFICATION_TITLE="‚ùå Tests Failed"
            fi
          else
            NOTIFICATION_COLOR=3066993   # Green for success
            NOTIFICATION_TITLE="‚úÖ All Tests Passed"
          fi
          
          if [ "$TOTAL_TESTS" -gt 0 ]; then
            # Get branch name
            BRANCH_NAME="${GITHUB_REF#refs/heads/}"
            
            # Get commit info
            COMMIT_SHA="${GITHUB_SHA:0:7}"
            COMMIT_MSG=$(git log -1 --pretty=%B | head -n 1)
            COMMIT_AUTHOR=$(git log -1 --pretty=%an)
            
            # Build Discord embed
            DISCORD_EMBED=$(cat <<EOF
          {
            "embeds": [{
              "title": "$NOTIFICATION_TITLE",
              "description": "**$TOTAL_TESTS_PASSED** passed, **$TOTAL_TESTS_FAILED** failed of **$TOTAL_TESTS** total tests | **$TOTAL_SUITES_PASSED** passed, **$TOTAL_SUITES_FAILED** failed of **$TOTAL_SUITES** total suites",
              "color": $NOTIFICATION_COLOR,
              "fields": [
                {
                  "name": "Repository",
                  "value": "[${{ github.repository }}](${{ github.server_url }}/${{ github.repository }})",
                  "inline": true
                },
                {
                  "name": "Branch",
                  "value": "\`$BRANCH_NAME\`",
                  "inline": true
                },
                {
                  "name": "Commit",
                  "value": "[\`$COMMIT_SHA\`](${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }})",
                  "inline": true
                },
                {
                  "name": "Author",
                  "value": "$COMMIT_AUTHOR",
                  "inline": true
                },
                {
                  "name": "Test Suites",
                  "value": "‚úÖ $TOTAL_SUITES_PASSED passed | ‚ùå $TOTAL_SUITES_FAILED failed | üìä $TOTAL_SUITES total",
                  "inline": false
                },
                {
                  "name": "Tests",
                  "value": "‚úÖ $TOTAL_TESTS_PASSED passed | ‚ùå $TOTAL_TESTS_FAILED failed | üìä $TOTAL_TESTS total",
                  "inline": false
                },
                {
                  "name": "E2E Tests",
                  "value": "$(if [ \"$E2E_STATUS\" = \"success\" ]; then echo '‚úÖ Passed'; elif [ \"$E2E_STATUS\" = \"failure\" ]; then echo '‚ùå Failed'; elif [ \"$E2E_STATUS\" = \"skipped\" ]; then echo '‚è≠Ô∏è Skipped'; else echo '‚ö†Ô∏è $E2E_STATUS'; fi)",
                  "inline": false
                },
                {
                  "name": "Failed Groups",
                  "value": "$(echo -e "$FAILED_GROUPS" | head -c 1000)",
                  "inline": false
                },
                {
                  "name": "Commit Message",
                  "value": "\`\`\`$COMMIT_MSG\`\`\`",
                  "inline": false
                },
                {
                  "name": "Workflow Run",
                  "value": "[View Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})",
                  "inline": false
                }
              ],
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%S.000Z)"
            }]
          }
          EOF
            )
            
            # Send to Discord (only if webhook URL is configured)
            DISCORD_WEBHOOK_URL="${{ secrets.DISCORD_WEBHOOK_URL }}"
            
            if [ -n "$DISCORD_WEBHOOK_URL" ]; then
              echo "Sending Discord notification..."
              curl -H "Content-Type: application/json" \
                   -d "$DISCORD_EMBED" \
                   "$DISCORD_WEBHOOK_URL" || echo "Failed to send Discord notification"
              
              echo "Discord notification sent - Title: $NOTIFICATION_TITLE"
            else
              echo "Discord webhook URL not configured - skipping notification"
            fi
          else
            echo "No tests found - no Discord notification sent"
          fi
